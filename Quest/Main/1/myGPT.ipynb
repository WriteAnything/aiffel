{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Transformer와 비교해 변경이 필요한 부분을 서술\n",
    "\n",
    "- GPT는 디코더만 사용하는 구조. 이를 위해 transformer의 아래를 변경해야 함\n",
    "    - 인코더 제거\n",
    "    - 디코더에 입력될 수 있도록 입력 조정\n",
    "    -   "
   ],
   "id": "c4a801896d0c0650"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. 모델의 입력 형태에 맞게 전처리를 수행하였다.",
   "id": "31047b875137d5ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T08:35:57.716624Z",
     "start_time": "2024-06-21T08:35:11.390632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 다운로드 및 경로 설정\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'cornell_movie_dialogs.zip',\n",
    "    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_dataset = os.path.join(\n",
    "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
    "\n",
    "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
    "path_to_movie_conversations = os.path.join(path_to_dataset,'movie_conversations.txt')\n",
    "\n",
    "# 대사와 대화 데이터를 로드하는 함수\n",
    "def load_conversations():\n",
    "    id2line = {}\n",
    "    with open(path_to_movie_lines, errors='ignore') as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "        id2line[parts[0]] = parts[4]\n",
    "\n",
    "    inputs, outputs = [], []\n",
    "    with open(path_to_movie_conversations, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "        conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "        for i in range(len(conversation) - 1):\n",
    "            inputs.append(id2line[conversation[i]])\n",
    "            outputs.append(id2line[conversation[i + 1]])\n",
    "\n",
    "            if len(inputs) >= MAX_SAMPLES:\n",
    "                return inputs, outputs\n",
    "    return inputs, outputs\n",
    "\n",
    "MAX_SAMPLES = 50000\n",
    "questions, answers = load_conversations()\n",
    "\n",
    "# 토크나이저 생성\n",
    "print(\"데이터셋 로드 중입니다...\")\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 토큰화 및 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "        \n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "    \n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    \n",
    "    return tokenized_inputs, tokenized_outputs\n",
    "\n",
    "MAX_LENGTH = 40\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "\n",
    "# 데이터셋 생성\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ],
   "id": "d02e7af2fc1892f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 17:35:11.647711: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-21 17:35:11.669289: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-21 17:35:11.669307: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-21 17:35:11.669994: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-21 17:35:11.674186: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-21 17:35:12.257036: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 로드 중입니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 17:35:29.956812: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-21 17:35:29.983679: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-21 17:35:29.983719: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-21 17:35:29.988158: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-21 17:35:29.988190: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-21 17:35:29.988207: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-21 17:35:30.126346: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-21 17:35:30.126388: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-21 17:35:30.126394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-21 17:35:30.126420: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-21 17:35:30.126434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13512 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. 모델의 입력 블록을 GPT 논문에 기반하여 수정하였다.",
   "id": "fae6fc9ab193d584"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T08:44:06.785359Z",
     "start_time": "2024-06-21T08:44:06.780688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ],
   "id": "5fa0994aecd4b85d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T08:44:19.606640Z",
     "start_time": "2024-06-21T08:44:19.601778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    # [[YOUR CODE]]\n",
    "    query = self.query_dense(query)  \n",
    "    key = self.key_dense(key)        \n",
    "    value = self.value_dense(value)  \n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    # [[YOUR CODE]]\n",
    "    query = self.split_heads(query, batch_size)  \n",
    "    key = self.split_heads(key, batch_size)      \n",
    "    value = self.split_heads(value, batch_size)  \n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ],
   "id": "9f6ebc01ad0c3eeb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T08:45:41.796868Z",
     "start_time": "2024-06-21T08:45:41.793466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ],
   "id": "dcb076234a3a6242",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T08:48:36.817678Z",
     "start_time": "2024-06-21T08:48:36.814948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ],
   "id": "139b16df8a16b749",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T08:55:06.070205Z",
     "start_time": "2024-06-21T08:55:06.064934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    # 인코더에서 들어오는 입력 삭제\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "    \n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션) 삭제\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention1)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, look_ahead_mask, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "\n",
    "# 입력 블록 수정 부분: Transformer의 인코더-디코더 구조에서 인코더를 제거하고, 디코더만 사용하는 구조로 변경. 입력 데이터는 디코더로 직접 전달.\n",
    "def gpt(vocab_size,\n",
    "        num_layers,\n",
    "        units,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        dropout,\n",
    "        max_position_encoding,\n",
    "        name=\"gpt\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    embedding = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    pos_encoding = PositionalEncoding(max_position_encoding, d_model)(embedding)\n",
    "\n",
    "    x = tf.keras.layers.Dropout(dropout)(pos_encoding)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        look_ahead_mask = create_look_ahead_mask(tf.shape(x)[1])\n",
    "        padding_mask = create_padding_mask(inputs)\n",
    "        x = decoder_layer(units, d_model, num_heads, dropout, name=f\"decoder_layer_{i}\")(\n",
    "            [x, look_ahead_mask, padding_mask])\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)"
   ],
   "id": "8cbcadaf9f51a3fe",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. GPT 모델을 정상적으로 구성하였다.\n",
   "id": "6a96fb4ab6818afa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T08:56:03.587575Z",
     "start_time": "2024-06-21T08:56:02.399285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)  # step 변수를 float 형식으로 변환\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = gpt(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()\n",
    "# 모델 학습\n",
    "gpt_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = gpt_model.fit(dataset, epochs=10, verbose=1)"
   ],
   "id": "b474acd66c4b28fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " inputs (InputLayer)         [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_13 (Embedding)    (None, None, 512)            4194304   ['inputs[0][0]']              \n",
      "                                                                                                  \n",
      " positional_encoding_13 (Po  (None, None, 512)            0         ['embedding_13[0][0]']        \n",
      " sitionalEncoding)                                                                                \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)        (None, None, 512)            0         ['positional_encoding_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_58 (TFO  (3,)                         0         ['dropout_61[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_58[0][0]'\n",
      " 06 (SlicingOpLambda)                                               ]                             \n",
      "                                                                                                  \n",
      " tf.ones_48 (TFOpLambda)     (None, None)                 0         ['tf.__operators__.getitem_106\n",
      "                                                                    [0][0]',                      \n",
      "                                                                     'tf.__operators__.getitem_106\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.math.equal_48 (TFOpLamb  (None, None)                 0         ['inputs[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.linalg.band_part_48 (TF  (None, None)                 0         ['tf.ones_48[0][0]']          \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.cast_48 (TFOpLambda)     (None, None)                 0         ['tf.math.equal_48[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.subtract_48 (TFOpL  (None, None)                 0         ['tf.linalg.band_part_48[0][0]\n",
      " ambda)                                                             ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 1, 1, None)           0         ['tf.cast_48[0][0]']          \n",
      " 07 (SlicingOpLambda)                                                                             \n",
      "                                                                                                  \n",
      " decoder_layer_0 (Functiona  (None, None, 512)            1577984   ['dropout_61[0][0]',          \n",
      " l)                                                                  'tf.math.subtract_48[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_107\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_59 (TFO  (3,)                         0         ['decoder_layer_0[0][0]']     \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_59[0][0]'\n",
      " 08 (SlicingOpLambda)                                               ]                             \n",
      "                                                                                                  \n",
      " tf.ones_49 (TFOpLambda)     (None, None)                 0         ['tf.__operators__.getitem_108\n",
      "                                                                    [0][0]',                      \n",
      "                                                                     'tf.__operators__.getitem_108\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.math.equal_49 (TFOpLamb  (None, None)                 0         ['inputs[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.linalg.band_part_49 (TF  (None, None)                 0         ['tf.ones_49[0][0]']          \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.cast_49 (TFOpLambda)     (None, None)                 0         ['tf.math.equal_49[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.subtract_49 (TFOpL  (None, None)                 0         ['tf.linalg.band_part_49[0][0]\n",
      " ambda)                                                             ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 1, 1, None)           0         ['tf.cast_49[0][0]']          \n",
      " 09 (SlicingOpLambda)                                                                             \n",
      "                                                                                                  \n",
      " decoder_layer_1 (Functiona  (None, None, 512)            1577984   ['decoder_layer_0[0][0]',     \n",
      " l)                                                                  'tf.math.subtract_49[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_109\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_60 (TFO  (3,)                         0         ['decoder_layer_1[0][0]']     \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_60[0][0]'\n",
      " 10 (SlicingOpLambda)                                               ]                             \n",
      "                                                                                                  \n",
      " tf.ones_50 (TFOpLambda)     (None, None)                 0         ['tf.__operators__.getitem_110\n",
      "                                                                    [0][0]',                      \n",
      "                                                                     'tf.__operators__.getitem_110\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.math.equal_50 (TFOpLamb  (None, None)                 0         ['inputs[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.linalg.band_part_50 (TF  (None, None)                 0         ['tf.ones_50[0][0]']          \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.cast_50 (TFOpLambda)     (None, None)                 0         ['tf.math.equal_50[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.subtract_50 (TFOpL  (None, None)                 0         ['tf.linalg.band_part_50[0][0]\n",
      " ambda)                                                             ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 1, 1, None)           0         ['tf.cast_50[0][0]']          \n",
      " 11 (SlicingOpLambda)                                                                             \n",
      "                                                                                                  \n",
      " decoder_layer_2 (Functiona  (None, None, 512)            1577984   ['decoder_layer_1[0][0]',     \n",
      " l)                                                                  'tf.math.subtract_50[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_111\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_61 (TFO  (3,)                         0         ['decoder_layer_2[0][0]']     \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_61[0][0]'\n",
      " 12 (SlicingOpLambda)                                               ]                             \n",
      "                                                                                                  \n",
      " tf.ones_51 (TFOpLambda)     (None, None)                 0         ['tf.__operators__.getitem_112\n",
      "                                                                    [0][0]',                      \n",
      "                                                                     'tf.__operators__.getitem_112\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.math.equal_51 (TFOpLamb  (None, None)                 0         ['inputs[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.linalg.band_part_51 (TF  (None, None)                 0         ['tf.ones_51[0][0]']          \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.cast_51 (TFOpLambda)     (None, None)                 0         ['tf.math.equal_51[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.subtract_51 (TFOpL  (None, None)                 0         ['tf.linalg.band_part_51[0][0]\n",
      " ambda)                                                             ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 1, 1, None)           0         ['tf.cast_51[0][0]']          \n",
      " 13 (SlicingOpLambda)                                                                             \n",
      "                                                                                                  \n",
      " decoder_layer_3 (Functiona  (None, None, 512)            1577984   ['decoder_layer_2[0][0]',     \n",
      " l)                                                                  'tf.math.subtract_51[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_113\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_62 (TFO  (3,)                         0         ['decoder_layer_3[0][0]']     \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_62[0][0]'\n",
      " 14 (SlicingOpLambda)                                               ]                             \n",
      "                                                                                                  \n",
      " tf.ones_52 (TFOpLambda)     (None, None)                 0         ['tf.__operators__.getitem_114\n",
      "                                                                    [0][0]',                      \n",
      "                                                                     'tf.__operators__.getitem_114\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.math.equal_52 (TFOpLamb  (None, None)                 0         ['inputs[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.linalg.band_part_52 (TF  (None, None)                 0         ['tf.ones_52[0][0]']          \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.cast_52 (TFOpLambda)     (None, None)                 0         ['tf.math.equal_52[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.subtract_52 (TFOpL  (None, None)                 0         ['tf.linalg.band_part_52[0][0]\n",
      " ambda)                                                             ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 1, 1, None)           0         ['tf.cast_52[0][0]']          \n",
      " 15 (SlicingOpLambda)                                                                             \n",
      "                                                                                                  \n",
      " decoder_layer_4 (Functiona  (None, None, 512)            1577984   ['decoder_layer_3[0][0]',     \n",
      " l)                                                                  'tf.math.subtract_52[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_115\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_63 (TFO  (3,)                         0         ['decoder_layer_4[0][0]']     \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_63[0][0]'\n",
      " 16 (SlicingOpLambda)                                               ]                             \n",
      "                                                                                                  \n",
      " tf.ones_53 (TFOpLambda)     (None, None)                 0         ['tf.__operators__.getitem_116\n",
      "                                                                    [0][0]',                      \n",
      "                                                                     'tf.__operators__.getitem_116\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.math.equal_53 (TFOpLamb  (None, None)                 0         ['inputs[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.linalg.band_part_53 (TF  (None, None)                 0         ['tf.ones_53[0][0]']          \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.cast_53 (TFOpLambda)     (None, None)                 0         ['tf.math.equal_53[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.subtract_53 (TFOpL  (None, None)                 0         ['tf.linalg.band_part_53[0][0]\n",
      " ambda)                                                             ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 1, 1, None)           0         ['tf.cast_53[0][0]']          \n",
      " 17 (SlicingOpLambda)                                                                             \n",
      "                                                                                                  \n",
      " decoder_layer_5 (Functiona  (None, None, 512)            1577984   ['decoder_layer_4[0][0]',     \n",
      " l)                                                                  'tf.math.subtract_53[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_117\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " outputs (Dense)             (None, None, 8192)           4202496   ['decoder_layer_5[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17864704 (68.15 MB)\n",
      "Trainable params: 17864704 (68.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/functional.py:642: UserWarning: Input dict contained keys ['dec_inputs'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'gpt' (type Functional).\n    \n    Input 1 of layer \"decoder_layer_0\" is incompatible with the layer: expected shape=(None, 1, None, None), found shape=(40, 40)\n    \n    Call arguments received by layer 'gpt' (type Functional):\n      • inputs={'inputs': 'tf.Tensor(shape=(None, 40), dtype=int32)', 'dec_inputs': 'tf.Tensor(shape=(None, 39), dtype=int32)'}\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# 모델 학습\u001B[39;00m\n\u001B[1;32m      5\u001B[0m gpt_model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m----> 6\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mgpt_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/tmp/__autograph_generated_file_y6qyet9.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/square/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'gpt' (type Functional).\n    \n    Input 1 of layer \"decoder_layer_0\" is incompatible with the layer: expected shape=(None, 1, None, None), found shape=(40, 40)\n    \n    Call arguments received by layer 'gpt' (type Functional):\n      • inputs={'inputs': 'tf.Tensor(shape=(None, 40), dtype=int32)', 'dec_inputs': 'tf.Tensor(shape=(None, 39), dtype=int32)'}\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d20fa64a6efe46fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
